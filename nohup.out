WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:16: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:17: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:18: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:19: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:20: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From main.py:147: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From main.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0522 00:52:15.130805 140546222774080 module_wrapper.py:139] From main.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From main.py:78: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0522 00:52:15.130919 140546222774080 module_wrapper.py:139] From main.py:78: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2021-05-22 00:52:15.131231: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2021-05-22 00:52:15.152166: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699850000 Hz
2021-05-22 00:52:15.152769: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b6b068e720 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-05-22 00:52:15.152782: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-05-22 00:52:15.154029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-05-22 00:52:15.231487: W tensorflow/compiler/xla/service/platform_util.cc:256] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 11552096256
2021-05-22 00:52:15.231959: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: no supported devices found for platform CUDA
Fatal Python error: Aborted

Current thread 0x00007fd377aed740 (most recent call first):
  File "/home/chenxubin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 699 in __init__
  File "/home/chenxubin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1585 in __init__
  File "main.py", line 78 in main
  File "/home/chenxubin/anaconda3/lib/python3.7/site-packages/absl/app.py", line 251 in _run_main
  File "/home/chenxubin/anaconda3/lib/python3.7/site-packages/absl/app.py", line 303 in run
  File "/home/chenxubin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py", line 40 in run
  File "main.py", line 147 in <module>
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:16: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:17: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:18: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:19: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:20: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From main.py:147: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From main.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0522 00:53:00.436580 140124560234304 module_wrapper.py:139] From main.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From main.py:78: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0522 00:53:00.436696 140124560234304 module_wrapper.py:139] From main.py:78: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2021-05-22 00:53:00.437019: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2021-05-22 00:53:00.460162: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699850000 Hz
2021-05-22 00:53:00.460497: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558d9739d570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-05-22 00:53:00.460510: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-05-22 00:53:00.461860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-05-22 00:53:00.535666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-22 00:53:00.536188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558d9742bf00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-05-22 00:53:00.536207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2021-05-22 00:53:00.536334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-22 00:53:00.536699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:08:00.0
2021-05-22 00:53:00.536803: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory
2021-05-22 00:53:00.536860: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory
2021-05-22 00:53:00.536908: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory
2021-05-22 00:53:00.536955: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory
2021-05-22 00:53:00.537008: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory
2021-05-22 00:53:00.537053: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory
2021-05-22 00:53:00.537097: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory
2021-05-22 00:53:00.537104: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-05-22 00:53:00.537114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-22 00:53:00.537119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2021-05-22 00:53:00.537123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:31: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0522 00:53:00.537740 140124560234304 module_wrapper.py:139] From /home/chenxubin/DCGAN-tensorflow/ops.py:31: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/model.py:108: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0522 00:53:02.643193 140124560234304 module_wrapper.py:139] From /home/chenxubin/DCGAN-tensorflow/model.py:108: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/ops.py:98: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0522 00:53:02.650027 140124560234304 module_wrapper.py:139] From /home/chenxubin/DCGAN-tensorflow/ops.py:98: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /home/chenxubin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0522 00:53:02.842885 140124560234304 deprecation.py:323] From /home/chenxubin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/model.py:156: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0522 00:53:02.858227 140124560234304 module_wrapper.py:139] From /home/chenxubin/DCGAN-tensorflow/model.py:156: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/model.py:161: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0522 00:53:02.858416 140124560234304 module_wrapper.py:139] From /home/chenxubin/DCGAN-tensorflow/model.py:161: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/model.py:164: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0522 00:53:02.878779 140124560234304 module_wrapper.py:139] From /home/chenxubin/DCGAN-tensorflow/model.py:164: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/chenxubin/DCGAN-tensorflow/model.py:169: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0522 00:53:03.327144 140124560234304 module_wrapper.py:139] From /home/chenxubin/DCGAN-tensorflow/model.py:169: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

{'?': <absl.app.HelpFlag object at 0x7f70d6bff668>,
 'G_img_sum': <absl.flags._flag.BooleanFlag object at 0x7f70c86a6d30>,
 'alsologtostderr': <absl.flags._flag.BooleanFlag object at 0x7f70e5061048>,
 'batch_size': <absl.flags._flag.Flag object at 0x7f70d958d5c0>,
 'beta1': <absl.flags._flag.Flag object at 0x7f70e25e7470>,
 'checkpoint_dir': <absl.flags._flag.Flag object at 0x7f70c86a6748>,
 'ckpt_freq': <absl.flags._flag.Flag object at 0x7f70c86a6ba8>,
 'crop': <absl.flags._flag.BooleanFlag object at 0x7f70c86a6860>,
 'data_dir': <absl.flags._flag.Flag object at 0x7f70c87004a8>,
 'dataset': <absl.flags._flag.Flag object at 0x7f70c86f72e8>,
 'epoch': <absl.flags._flag.Flag object at 0x7f714935aba8>,
 'export': <absl.flags._flag.BooleanFlag object at 0x7f70c86a6940>,
 'freeze': <absl.flags._flag.BooleanFlag object at 0x7f70c86a69b0>,
 'help': <absl.app.HelpFlag object at 0x7f70d6bff668>,
 'helpfull': <absl.app.HelpfullFlag object at 0x7f70c86a6e48>,
 'helpshort': <absl.app.HelpshortFlag object at 0x7f70c86a6dd8>,
 'helpxml': <absl.app.HelpXMLFlag object at 0x7f70c86a6eb8>,
 'input_fname_pattern': <absl.flags._flag.Flag object at 0x7f70c86f7be0>,
 'input_height': <absl.flags._flag.Flag object at 0x7f70c86eba58>,
 'input_width': <absl.flags._flag.Flag object at 0x7f70c86ebb38>,
 'learning_rate': <absl.flags._flag.Flag object at 0x7f71263aa908>,
 'log_dir': <absl.flags._flag.Flag object at 0x7f70e50610f0>,
 'logger_levels': <absl.logging._LoggerLevelsFlag object at 0x7f70e5061240>,
 'logtostderr': <absl.flags._flag.BooleanFlag object at 0x7f70e504ef28>,
 'max_to_keep': <absl.flags._flag.Flag object at 0x7f70c86a6a58>,
 'only_check_args': <absl.flags._flag.BooleanFlag object at 0x7f70e5061a58>,
 'op_conversion_fallback_to_while_loop': <absl.flags._flag.BooleanFlag object at 0x7f70e39b9320>,
 'out_dir': <absl.flags._flag.Flag object at 0x7f70c8700710>,
 'out_name': <absl.flags._flag.Flag object at 0x7f70c86a6320>,
 'output_height': <absl.flags._flag.Flag object at 0x7f70c86ebba8>,
 'output_width': <absl.flags._flag.Flag object at 0x7f70c86ebc88>,
 'pdb': <absl.flags._defines.DEFINE_alias.<locals>._FlagAlias object at 0x7f70e5061898>,
 'pdb_post_mortem': <absl.flags._flag.BooleanFlag object at 0x7f70e51b4b70>,
 'profile_file': <absl.flags._flag.Flag object at 0x7f70e50619b0>,
 'run_with_pdb': <absl.flags._flag.BooleanFlag object at 0x7f70e51b4a58>,
 'run_with_profiling': <absl.flags._flag.BooleanFlag object at 0x7f70e5061908>,
 'sample_dir': <absl.flags._flag.Flag object at 0x7f70c86a67b8>,
 'sample_freq': <absl.flags._flag.Flag object at 0x7f70c86a6b00>,
 'showprefixforinfo': <absl.flags._flag.BooleanFlag object at 0x7f70e50614a8>,
 'stderrthreshold': <absl.logging._StderrthresholdFlag object at 0x7f70e50613c8>,
 'test_random_seed': <absl.flags._flag.Flag object at 0x7f7144f7efd0>,
 'test_randomize_ordering_seed': <absl.flags._flag.Flag object at 0x7f7144f0d080>,
 'test_srcdir': <absl.flags._flag.Flag object at 0x7f7144f6fb70>,
 'test_tmpdir': <absl.flags._flag.Flag object at 0x7f7144f795f8>,
 'train': <absl.flags._flag.BooleanFlag object at 0x7f70c86a67f0>,
 'train_size': <absl.flags._flag.Flag object at 0x7f70e25e7c50>,
 'use_cprofile_for_profiling': <absl.flags._flag.BooleanFlag object at 0x7f70e50619e8>,
 'v': <absl.logging._VerbosityFlag object at 0x7f70e5061160>,
 'verbosity': <absl.logging._VerbosityFlag object at 0x7f70e5061160>,
 'visualize': <absl.flags._flag.BooleanFlag object at 0x7f70c86a68d0>,
 'xml_output_file': <absl.flags._flag.Flag object at 0x7f7144f0d128>,
 'z_dim': <absl.flags._flag.Flag object at 0x7f70c86a6c50>,
 'z_dist': <absl.flags._flag.Flag object at 0x7f70c86a6cf8>}
---------
Variables: name (type shape) [size]
---------
generator/g_h0_lin/Matrix:0 (float32_ref 110x1024) [112640, bytes: 450560]
generator/g_h0_lin/bias:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_bn0/beta:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_bn0/gamma:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_h1_lin/Matrix:0 (float32_ref 1034x6272) [6485248, bytes: 25940992]
generator/g_h1_lin/bias:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_bn1/beta:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_bn1/gamma:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_h2/w:0 (float32_ref 5x5x128x138) [441600, bytes: 1766400]
generator/g_h2/biases:0 (float32_ref 128) [128, bytes: 512]
generator/g_bn2/beta:0 (float32_ref 128) [128, bytes: 512]
generator/g_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]
generator/g_h3/w:0 (float32_ref 5x5x1x138) [3450, bytes: 13800]
generator/g_h3/biases:0 (float32_ref 1) [1, bytes: 4]
discriminator/d_h0_conv/w:0 (float32_ref 5x5x11x11) [3025, bytes: 12100]
discriminator/d_h0_conv/biases:0 (float32_ref 11) [11, bytes: 44]
discriminator/d_h1_conv/w:0 (float32_ref 5x5x21x74) [38850, bytes: 155400]
discriminator/d_h1_conv/biases:0 (float32_ref 74) [74, bytes: 296]
discriminator/d_bn1/beta:0 (float32_ref 74) [74, bytes: 296]
discriminator/d_bn1/gamma:0 (float32_ref 74) [74, bytes: 296]
discriminator/d_h2_lin/Matrix:0 (float32_ref 3636x1024) [3723264, bytes: 14893056]
discriminator/d_h2_lin/bias:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_bn2/beta:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_bn2/gamma:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_h3_lin/Matrix:0 (float32_ref 1034x1) [1034, bytes: 4136]
discriminator/d_h3_lin/bias:0 (float32_ref 1) [1, bytes: 4]
Total size of variables: 10834690
Total bytes of variables: 43338760
 [*] Reading checkpoints... ./out/20210522.005300 - data - mnist - x28.z100.uniform_signed.y28.b256/checkpoint
 [*] Failed to find a checkpoint
 [!] Load failed...
[       1 Epoch:[ 0/25] [   0/ 273] time: 1.2979, d_loss: 1.95049906, g_loss: 0.98549086
[       2 Epoch:[ 0/25] [   1/ 273] time: 2.0466, d_loss: 1.45858026, g_loss: 0.73961365
[       3 Epoch:[ 0/25] [   2/ 273] time: 2.8110, d_loss: 1.50949979, g_loss: 0.74329090
[       4 Epoch:[ 0/25] [   3/ 273] time: 3.5637, d_loss: 1.42055249, g_loss: 0.72233856
[       5 Epoch:[ 0/25] [   4/ 273] time: 4.3170, d_loss: 1.38442254, g_loss: 0.71325624
[       6 Epoch:[ 0/25] [   5/ 273] time: 5.0734, d_loss: 1.39128995, g_loss: 0.71021062
[       7 Epoch:[ 0/25] [   6/ 273] time: 5.8283, d_loss: 1.37664723, g_loss: 0.70810199
[       8 Epoch:[ 0/25] [   7/ 273] time: 6.5858, d_loss: 1.38129854, g_loss: 0.71030962
[       9 Epoch:[ 0/25] [   8/ 273] time: 7.3454, d_loss: 1.38175368, g_loss: 0.70295441
[      10 Epoch:[ 0/25] [   9/ 273] time: 8.1051, d_loss: 1.37156522, g_loss: 0.70294857
[      11 Epoch:[ 0/25] [  10/ 273] time: 8.8696, d_loss: 1.37125754, g_loss: 0.70680177
[      12 Epoch:[ 0/25] [  11/ 273] time: 9.6205, d_loss: 1.38285279, g_loss: 0.71015912
[      13 Epoch:[ 0/25] [  12/ 273] time: 10.3774, d_loss: 1.39104998, g_loss: 0.71864688
[      14 Epoch:[ 0/25] [  13/ 273] time: 11.1344, d_loss: 1.39237952, g_loss: 0.71752584
[      15 Epoch:[ 0/25] [  14/ 273] time: 11.8860, d_loss: 1.39907706, g_loss: 0.71879560
[      16 Epoch:[ 0/25] [  15/ 273] time: 12.6417, d_loss: 1.39320290, g_loss: 0.70692009
[      17 Epoch:[ 0/25] [  16/ 273] time: 13.3995, d_loss: 1.37445426, g_loss: 0.70212376
[      18 Epoch:[ 0/25] [  17/ 273] time: 14.1582, d_loss: 1.37958288, g_loss: 0.69824237
[      19 Epoch:[ 0/25] [  18/ 273] time: 14.9226, d_loss: 1.37832856, g_loss: 0.69743216
[      20 Epoch:[ 0/25] [  19/ 273] time: 15.6750, d_loss: 1.38185549, g_loss: 0.69843400
[      21 Epoch:[ 0/25] [  20/ 273] time: 16.4425, d_loss: 1.38754463, g_loss: 0.69546944
[      22 Epoch:[ 0/25] [  21/ 273] time: 17.1926, d_loss: 1.38478112, g_loss: 0.70108080
[      23 Epoch:[ 0/25] [  22/ 273] time: 17.9497, d_loss: 1.38516009, g_loss: 0.70004910
[      24 Epoch:[ 0/25] [  23/ 273] time: 18.7069, d_loss: 1.40141988, g_loss: 0.71412247
[      25 Epoch:[ 0/25] [  24/ 273] time: 19.4662, d_loss: 1.43791676, g_loss: 0.72450113
[      26 Epoch:[ 0/25] [  25/ 273] time: 20.2216, d_loss: 1.40929604, g_loss: 0.70802873
[      27 Epoch:[ 0/25] [  26/ 273] time: 20.9905, d_loss: 1.40597236, g_loss: 0.70462847
[      28 Epoch:[ 0/25] [  27/ 273] time: 21.7460, d_loss: 1.41150284, g_loss: 0.72129846
[      29 Epoch:[ 0/25] [  28/ 273] time: 22.4992, d_loss: 1.39340448, g_loss: 0.71097159
[      30 Epoch:[ 0/25] [  29/ 273] time: 23.2654, d_loss: 1.38236356, g_loss: 0.70249164
[      31 Epoch:[ 0/25] [  30/ 273] time: 24.0132, d_loss: 1.38420343, g_loss: 0.70922005
[      32 Epoch:[ 0/25] [  31/ 273] time: 24.7718, d_loss: 1.38101792, g_loss: 0.70225483
[      33 Epoch:[ 0/25] [  32/ 273] time: 25.5382, d_loss: 1.37755787, g_loss: 0.69774526
[      34 Epoch:[ 0/25] [  33/ 273] time: 26.2876, d_loss: 1.37847543, g_loss: 0.70708019
[      35 Epoch:[ 0/25] [  34/ 273] time: 27.0561, d_loss: 1.37709951, g_loss: 0.70268083
[      36 Epoch:[ 0/25] [  35/ 273] time: 27.8371, d_loss: 1.37752235, g_loss: 0.69903541
[      37 Epoch:[ 0/25] [  36/ 273] time: 28.6078, d_loss: 1.37853646, g_loss: 0.69555694
[      38 Epoch:[ 0/25] [  37/ 273] time: 29.3894, d_loss: 1.38102484, g_loss: 0.69663960
[      39 Epoch:[ 0/25] [  38/ 273] time: 30.1567, d_loss: 1.38271868, g_loss: 0.69553220
[      40 Epoch:[ 0/25] [  39/ 273] time: 30.9064, d_loss: 1.38553762, g_loss: 0.69704622
[      41 Epoch:[ 0/25] [  40/ 273] time: 31.6690, d_loss: 1.38806272, g_loss: 0.70018870
[      42 Epoch:[ 0/25] [  41/ 273] time: 32.4303, d_loss: 1.38893890, g_loss: 0.69754177
[      43 Epoch:[ 0/25] [  42/ 273] time: 33.1814, d_loss: 1.39791727, g_loss: 0.69862843
[      44 Epoch:[ 0/25] [  43/ 273] time: 33.9344, d_loss: 1.40835917, g_loss: 0.70945919
[      45 Epoch:[ 0/25] [  44/ 273] time: 34.6807, d_loss: 1.41866195, g_loss: 0.70616627
[      46 Epoch:[ 0/25] [  45/ 273] time: 35.4229, d_loss: 1.41156077, g_loss: 0.70238400
[      47 Epoch:[ 0/25] [  46/ 273] time: 36.1730, d_loss: 1.42400289, g_loss: 0.70512712
[      48 Epoch:[ 0/25] [  47/ 273] time: 36.9278, d_loss: 1.41432846, g_loss: 0.70663226
[      49 Epoch:[ 0/25] [  48/ 273] time: 37.6733, d_loss: 1.40709209, g_loss: 0.69786668
[      50 Epoch:[ 0/25] [  49/ 273] time: 38.4233, d_loss: 1.40293503, g_loss: 0.69552279
[      51 Epoch:[ 0/25] [  50/ 273] time: 39.1757, d_loss: 1.40772772, g_loss: 0.69744492
[      52 Epoch:[ 0/25] [  51/ 273] time: 39.9119, d_loss: 1.39793777, g_loss: 0.69196731
[      53 Epoch:[ 0/25] [  52/ 273] time: 40.6513, d_loss: 1.39418566, g_loss: 0.69675028
[      54 Epoch:[ 0/25] [  53/ 273] time: 41.3936, d_loss: 1.39568448, g_loss: 0.69202685
[      55 Epoch:[ 0/25] [  54/ 273] time: 42.1324, d_loss: 1.39062154, g_loss: 0.69564503
[      56 Epoch:[ 0/25] [  55/ 273] time: 42.8745, d_loss: 1.39368582, g_loss: 0.69557750
[      57 Epoch:[ 0/25] [  56/ 273] time: 43.6211, d_loss: 1.39195085, g_loss: 0.69365788
[      58 Epoch:[ 0/25] [  57/ 273] time: 44.3700, d_loss: 1.39298594, g_loss: 0.69186455
[      59 Epoch:[ 0/25] [  58/ 273] time: 45.1168, d_loss: 1.39464402, g_loss: 0.69120574
[      60 Epoch:[ 0/25] [  59/ 273] time: 45.8619, d_loss: 1.39606166, g_loss: 0.68756932
[      61 Epoch:[ 0/25] [  60/ 273] time: 46.6016, d_loss: 1.39539766, g_loss: 0.69136000
[      62 Epoch:[ 0/25] [  61/ 273] time: 47.3504, d_loss: 1.39193976, g_loss: 0.69553149
[      63 Epoch:[ 0/25] [  62/ 273] time: 48.1007, d_loss: 1.39462662, g_loss: 0.68973523
[      64 Epoch:[ 0/25] [  63/ 273] time: 48.8421, d_loss: 1.39528155, g_loss: 0.69721746
[      65 Epoch:[ 0/25] [  64/ 273] time: 49.5873, d_loss: 1.39208484, g_loss: 0.69439268
[      66 Epoch:[ 0/25] [  65/ 273] time: 50.3350, d_loss: 1.39289653, g_loss: 0.68998563
[      67 Epoch:[ 0/25] [  66/ 273] time: 51.0882, d_loss: 1.39376223, g_loss: 0.68956238
[      68 Epoch:[ 0/25] [  67/ 273] time: 51.8318, d_loss: 1.39549148, g_loss: 0.68953347
[      69 Epoch:[ 0/25] [  68/ 273] time: 52.5766, d_loss: 1.39705813, g_loss: 0.69279206
[      70 Epoch:[ 0/25] [  69/ 273] time: 53.3191, d_loss: 1.39701617, g_loss: 0.69368112
[      71 Epoch:[ 0/25] [  70/ 273] time: 54.0672, d_loss: 1.39484453, g_loss: 0.69540817
[      72 Epoch:[ 0/25] [  71/ 273] time: 54.8133, d_loss: 1.39550877, g_loss: 0.69436419
[      73 Epoch:[ 0/25] [  72/ 273] time: 55.5612, d_loss: 1.39175558, g_loss: 0.69203591
[      74 Epoch:[ 0/25] [  73/ 273] time: 56.3081, d_loss: 1.39076567, g_loss: 0.68835914
[      75 Epoch:[ 0/25] [  74/ 273] time: 57.3041, d_loss: 1.39664602, g_loss: 0.68672001
[      76 Epoch:[ 0/25] [  75/ 273] time: 58.1755, d_loss: 1.39870322, g_loss: 0.68965256
[      77 Epoch:[ 0/25] [  76/ 273] time: 58.9346, d_loss: 1.39549565, g_loss: 0.68745577
[      78 Epoch:[ 0/25] [  77/ 273] time: 59.6880, d_loss: 1.39557362, g_loss: 0.68724453
[      79 Epoch:[ 0/25] [  78/ 273] time: 60.4322, d_loss: 1.39315581, g_loss: 0.68780613
[      80 Epoch:[ 0/25] [  79/ 273] time: 61.1935, d_loss: 1.39232039, g_loss: 0.68965340
[      81 Epoch:[ 0/25] [  80/ 273] time: 61.9491, d_loss: 1.39206433, g_loss: 0.68850833
[      82 Epoch:[ 0/25] [  81/ 273] time: 62.6944, d_loss: 1.39612556, g_loss: 0.69735968
[      83 Epoch:[ 0/25] [  82/ 273] time: 63.4579, d_loss: 1.39748263, g_loss: 0.69550717
[      84 Epoch:[ 0/25] [  83/ 273] time: 64.2137, d_loss: 1.40054035, g_loss: 0.69709188
[      85 Epoch:[ 0/25] [  84/ 273] time: 64.9643, d_loss: 1.39660645, g_loss: 0.69284558
[      86 Epoch:[ 0/25] [  85/ 273] time: 65.7241, d_loss: 1.39255524, g_loss: 0.69189811
[      87 Epoch:[ 0/25] [  86/ 273] time: 66.4835, d_loss: 1.39352894, g_loss: 0.69520396
[      88 Epoch:[ 0/25] [  87/ 273] time: 67.2298, d_loss: 1.39596438, g_loss: 0.68763280
[      89 Epoch:[ 0/25] [  88/ 273] time: 67.9942, d_loss: 1.39677525, g_loss: 0.69501048
[      90 Epoch:[ 0/25] [  89/ 273] time: 68.7537, d_loss: 1.39215136, g_loss: 0.69319844
[      91 Epoch:[ 0/25] [  90/ 273] time: 69.5037, d_loss: 1.39286196, g_loss: 0.69229460
[      92 Epoch:[ 0/25] [  91/ 273] time: 70.2692, d_loss: 1.39309657, g_loss: 0.69107074
[      93 Epoch:[ 0/25] [  92/ 273] time: 71.0330, d_loss: 1.39226127, g_loss: 0.69264346
[      94 Epoch:[ 0/25] [  93/ 273] time: 71.7875, d_loss: 1.39310384, g_loss: 0.69070077
[      95 Epoch:[ 0/25] [  94/ 273] time: 72.5593, d_loss: 1.39361978, g_loss: 0.69452453
[      96 Epoch:[ 0/25] [  95/ 273] time: 73.3198, d_loss: 1.39688301, g_loss: 0.69270968
[      97 Epoch:[ 0/25] [  96/ 273] time: 74.0733, d_loss: 1.40676236, g_loss: 0.70058763
[      98 Epoch:[ 0/25] [  97/ 273] time: 74.8450, d_loss: 1.40656114, g_loss: 0.69451439
[      99 Epoch:[ 0/25] [  98/ 273] time: 75.6106, d_loss: 1.40152967, g_loss: 0.69254529
[     100 Epoch:[ 0/25] [  99/ 273] time: 76.3718, d_loss: 1.40072072, g_loss: 0.68800044
[     101 Epoch:[ 0/25] [ 100/ 273] time: 77.1365, d_loss: 1.39600825, g_loss: 0.69304067
[     102 Epoch:[ 0/25] [ 101/ 273] time: 77.9046, d_loss: 1.39512885, g_loss: 0.69370985
[     103 Epoch:[ 0/25] [ 102/ 273] time: 78.6574, d_loss: 1.39873981, g_loss: 0.69690758
[     104 Epoch:[ 0/25] [ 103/ 273] time: 79.4252, d_loss: 1.39510584, g_loss: 0.69760066
[     105 Epoch:[ 0/25] [ 104/ 273] time: 80.1899, d_loss: 1.39356494, g_loss: 0.69522500
[     106 Epoch:[ 0/25] [ 105/ 273] time: 80.9411, d_loss: 1.39222074, g_loss: 0.69075584
[     107 Epoch:[ 0/25] [ 106/ 273] time: 81.7046, d_loss: 1.39100409, g_loss: 0.69016856
[     108 Epoch:[ 0/25] [ 107/ 273] time: 82.4611, d_loss: 1.39479613, g_loss: 0.69272017
[     109 Epoch:[ 0/25] [ 108/ 273] time: 83.2149, d_loss: 1.40411174, g_loss: 0.69770384
[     110 Epoch:[ 0/25] [ 109/ 273] time: 83.9749, d_loss: 1.39985466, g_loss: 0.69587594
[     111 Epoch:[ 0/25] [ 110/ 273] time: 84.7328, d_loss: 1.39486504, g_loss: 0.69199944
[     112 Epoch:[ 0/25] [ 111/ 273] time: 85.4941, d_loss: 1.39672565, g_loss: 0.69582760
[     113 Epoch:[ 0/25] [ 112/ 273] time: 86.2534, d_loss: 1.39493382, g_loss: 0.69767630
[     114 Epoch:[ 0/25] [ 113/ 273] time: 87.0119, d_loss: 1.39148331, g_loss: 0.69623649
[     115 Epoch:[ 0/25] [ 114/ 273] time: 87.7733, d_loss: 1.39362800, g_loss: 0.69431055
[     116 Epoch:[ 0/25] [ 115/ 273] time: 88.5337, d_loss: 1.39724171, g_loss: 0.69530600
[     117 Epoch:[ 0/25] [ 116/ 273] time: 89.2884, d_loss: 1.39907634, g_loss: 0.69240957
[     118 Epoch:[ 0/25] [ 117/ 273] time: 90.0447, d_loss: 1.40694022, g_loss: 0.69720280
[     119 Epoch:[ 0/25] [ 118/ 273] time: 90.8106, d_loss: 1.40026081, g_loss: 0.68899834
[     120 Epoch:[ 0/25] [ 119/ 273] time: 91.5722, d_loss: 1.39832067, g_loss: 0.69097084
[     121 Epoch:[ 0/25] [ 120/ 273] time: 92.3207, d_loss: 1.40437841, g_loss: 0.69845903
[     122 Epoch:[ 0/25] [ 121/ 273] time: 93.0959, d_loss: 1.39819694, g_loss: 0.69677854
[     123 Epoch:[ 0/25] [ 122/ 273] time: 93.8523, d_loss: 1.39615345, g_loss: 0.69780564
[     124 Epoch:[ 0/25] [ 123/ 273] time: 94.6108, d_loss: 1.38893259, g_loss: 0.69766796
[     125 Epoch:[ 0/25] [ 124/ 273] time: 95.3635, d_loss: 1.38526046, g_loss: 0.69197410
[     126 Epoch:[ 0/25] [ 125/ 273] time: 96.1199, d_loss: 1.38654399, g_loss: 0.69027871
[     127 Epoch:[ 0/25] [ 126/ 273] time: 96.8790, d_loss: 1.38942838, g_loss: 0.69138062
[     128 Epoch:[ 0/25] [ 127/ 273] time: 97.6400, d_loss: 1.38976574, g_loss: 0.68878877
[     129 Epoch:[ 0/25] [ 128/ 273] time: 98.3993, d_loss: 1.39660120, g_loss: 0.69320011
[     130 Epoch:[ 0/25] [ 129/ 273] time: 99.1582, d_loss: 1.39418113, g_loss: 0.68971920
[     131 Epoch:[ 0/25] [ 130/ 273] time: 99.9155, d_loss: 1.39646006, g_loss: 0.69181973
[     132 Epoch:[ 0/25] [ 131/ 273] time: 100.6765, d_loss: 1.39665842, g_loss: 0.69163489
[     133 Epoch:[ 0/25] [ 132/ 273] time: 101.4369, d_loss: 1.39450765, g_loss: 0.69046885
[     134 Epoch:[ 0/25] [ 133/ 273] time: 102.1934, d_loss: 1.39286816, g_loss: 0.69254839
[     135 Epoch:[ 0/25] [ 134/ 273] time: 102.9515, d_loss: 1.39196563, g_loss: 0.69453996
[     136 Epoch:[ 0/25] [ 135/ 273] time: 103.7159, d_loss: 1.39132881, g_loss: 0.69282609
[     137 Epoch:[ 0/25] [ 136/ 273] time: 104.4789, d_loss: 1.38922954, g_loss: 0.69275481
[     138 Epoch:[ 0/25] [ 137/ 273] time: 105.2421, d_loss: 1.38739955, g_loss: 0.69165963
[     139 Epoch:[ 0/25] [ 138/ 273] time: 105.9992, d_loss: 1.38703084, g_loss: 0.69109082
[     140 Epoch:[ 0/25] [ 139/ 273] time: 106.7646, d_loss: 1.38986719, g_loss: 0.68899262
[     141 Epoch:[ 0/25] [ 140/ 273] time: 107.5198, d_loss: 1.38911450, g_loss: 0.69406295
[     142 Epoch:[ 0/25] [ 141/ 273] time: 108.2840, d_loss: 1.38805389, g_loss: 0.69322819
[     143 Epoch:[ 0/25] [ 142/ 273] time: 109.0398, d_loss: 1.39010000, g_loss: 0.68829834
[     144 Epoch:[ 0/25] [ 143/ 273] time: 109.7970, d_loss: 1.39308679, g_loss: 0.69452924
[     145 Epoch:[ 0/25] [ 144/ 273] time: 110.5603, d_loss: 1.39605904, g_loss: 0.69136608
[     146 Epoch:[ 0/25] [ 145/ 273] time: 111.3210, d_loss: 1.39157963, g_loss: 0.69427109
[     147 Epoch:[ 0/25] [ 146/ 273] time: 112.1002, d_loss: 1.39004815, g_loss: 0.69279742
[     148 Epoch:[ 0/25] [ 147/ 273] time: 112.8866, d_loss: 1.38940918, g_loss: 0.69232571
[     149 Epoch:[ 0/25] [ 148/ 273] time: 113.6955, d_loss: 1.38909030, g_loss: 0.69231224
[     150 Epoch:[ 0/25] [ 149/ 273] time: 114.5161, d_loss: 1.39360273, g_loss: 0.69116277
[     151 Epoch:[ 0/25] [ 150/ 273] time: 115.3153, d_loss: 1.39808977, g_loss: 0.69673264
[     152 Epoch:[ 0/25] [ 151/ 273] time: 116.1288, d_loss: 1.39454889, g_loss: 0.69358993
[     153 Epoch:[ 0/25] [ 152/ 273] time: 116.9310, d_loss: 1.39307165, g_loss: 0.69178510
[     154 Epoch:[ 0/25] [ 153/ 273] time: 117.7299, d_loss: 1.39445937, g_loss: 0.69687653
[     155 Epoch:[ 0/25] [ 154/ 273] time: 118.5356, d_loss: 1.39271009, g_loss: 0.69447547
[     156 Epoch:[ 0/25] [ 155/ 273] time: 119.3670, d_loss: 1.39304066, g_loss: 0.69615412
[     157 Epoch:[ 0/25] [ 156/ 273] time: 120.1879, d_loss: 1.39497328, g_loss: 0.69606113
[     158 Epoch:[ 0/25] [ 157/ 273] time: 120.9993, d_loss: 1.39525080, g_loss: 0.69665122
[     159 Epoch:[ 0/25] [ 158/ 273] time: 121.7826, d_loss: 1.39404237, g_loss: 0.69373071
[     160 Epoch:[ 0/25] [ 159/ 273] time: 122.5959, d_loss: 1.39251244, g_loss: 0.69714761
[     161 Epoch:[ 0/25] [ 160/ 273] time: 123.4084, d_loss: 1.39068377, g_loss: 0.69018853
[     162 Epoch:[ 0/25] [ 161/ 273] time: 124.2130, d_loss: 1.39238596, g_loss: 0.69382697
[     163 Epoch:[ 0/25] [ 162/ 273] time: 125.0154, d_loss: 1.39708900, g_loss: 0.69102502
[     164 Epoch:[ 0/25] [ 163/ 273] time: 125.8249, d_loss: 1.39486027, g_loss: 0.69038761
[     165 Epoch:[ 0/25] [ 164/ 273] time: 126.5898, d_loss: 1.39474630, g_loss: 0.68805480
[     166 Epoch:[ 0/25] [ 165/ 273] time: 127.3477, d_loss: 1.39840758, g_loss: 0.69125724
[     167 Epoch:[ 0/25] [ 166/ 273] time: 128.1094, d_loss: 1.39972007, g_loss: 0.69105989
[     168 Epoch:[ 0/25] [ 167/ 273] time: 128.8600, d_loss: 1.39995778, g_loss: 0.69978535
[     169 Epoch:[ 0/25] [ 168/ 273] time: 129.6175, d_loss: 1.39462852, g_loss: 0.69497371
[     170 Epoch:[ 0/25] [ 169/ 273] time: 130.3780, d_loss: 1.39515483, g_loss: 0.69688010
[     171 Epoch:[ 0/25] [ 170/ 273] time: 131.1292, d_loss: 1.39072156, g_loss: 0.69614315
[     172 Epoch:[ 0/25] [ 171/ 273] time: 131.8865, d_loss: 1.39013767, g_loss: 0.69487667
[     173 Epoch:[ 0/25] [ 172/ 273] time: 132.6521, d_loss: 1.39074278, g_loss: 0.69240111
[     174 Epoch:[ 0/25] [ 173/ 273] time: 133.4076, d_loss: 1.38957953, g_loss: 0.68972903
[     175 Epoch:[ 0/25] [ 174/ 273] time: 134.1670, d_loss: 1.39108968, g_loss: 0.69472849
[     176 Epoch:[ 0/25] [ 175/ 273] time: 134.9273, d_loss: 1.39278030, g_loss: 0.70136052
[     177 Epoch:[ 0/25] [ 176/ 273] time: 135.6787, d_loss: 1.39121413, g_loss: 0.69570541
[     178 Epoch:[ 0/25] [ 177/ 273] time: 136.4357, d_loss: 1.39091289, g_loss: 0.69304538
[     179 Epoch:[ 0/25] [ 178/ 273] time: 137.2021, d_loss: 1.39018607, g_loss: 0.69126046
[     180 Epoch:[ 0/25] [ 179/ 273] time: 137.9573, d_loss: 1.39360285, g_loss: 0.69140828
[     181 Epoch:[ 0/25] [ 180/ 273] time: 138.7217, d_loss: 1.39797354, g_loss: 0.68888140
[     182 Epoch:[ 0/25] [ 181/ 273] time: 139.4825, d_loss: 1.40035582, g_loss: 0.69517839
[     183 Epoch:[ 0/25] [ 182/ 273] time: 140.2352, d_loss: 1.39532781, g_loss: 0.69283605
[     184 Epoch:[ 0/25] [ 183/ 273] time: 140.9907, d_loss: 1.39221740, g_loss: 0.69075978
[     185 Epoch:[ 0/25] [ 184/ 273] time: 141.7464, d_loss: 1.39494538, g_loss: 0.69572604
[     186 Epoch:[ 0/25] [ 185/ 273] time: 142.5038, d_loss: 1.39044046, g_loss: 0.69378448
[     187 Epoch:[ 0/25] [ 186/ 273] time: 143.2640, d_loss: 1.38832068, g_loss: 0.69699484
[     188 Epoch:[ 0/25] [ 187/ 273] time: 144.0244, d_loss: 1.38837290, g_loss: 0.69239783
[     189 Epoch:[ 0/25] [ 188/ 273] time: 144.7840, d_loss: 1.38784218, g_loss: 0.69459915
[     190 Epoch:[ 0/25] [ 189/ 273] time: 145.5490, d_loss: 1.38849008, g_loss: 0.69098485
[     191 Epoch:[ 0/25] [ 190/ 273] time: 146.3120, d_loss: 1.38772988, g_loss: 0.69391376
[     192 Epoch:[ 0/25] [ 191/ 273] time: 147.0747, d_loss: 1.38845766, g_loss: 0.69358492
[     193 Epoch:[ 0/25] [ 192/ 273] time: 147.8320, d_loss: 1.39022183, g_loss: 0.69223166
[     194 Epoch:[ 0/25] [ 193/ 273] time: 148.5953, d_loss: 1.39064884, g_loss: 0.69560653
[     195 Epoch:[ 0/25] [ 194/ 273] time: 149.3461, d_loss: 1.39022541, g_loss: 0.69359493
[     196 Epoch:[ 0/25] [ 195/ 273] time: 150.0994, d_loss: 1.38980055, g_loss: 0.69467431
[     197 Epoch:[ 0/25] [ 196/ 273] time: 150.8623, d_loss: 1.39127314, g_loss: 0.68947369
[     198 Epoch:[ 0/25] [ 197/ 273] time: 151.6217, d_loss: 1.39002776, g_loss: 0.69312429
[     199 Epoch:[ 0/25] [ 198/ 273] time: 152.3782, d_loss: 1.38789725, g_loss: 0.69295931
[     200 Epoch:[ 0/25] [ 199/ 273] time: 153.1385, d_loss: 1.38857687, g_loss: 0.69173789
[Sample] d_loss: 1.38671505, g_loss: 0.69202906
[     201 Epoch:[ 0/25] [ 200/ 273] time: 154.2528, d_loss: 1.38986659, g_loss: 0.69019210
[     202 Epoch:[ 0/25] [ 201/ 273] time: 155.0155, d_loss: 1.38799810, g_loss: 0.69061399
[     203 Epoch:[ 0/25] [ 202/ 273] time: 155.7774, d_loss: 1.38848758, g_loss: 0.69132340
[     204 Epoch:[ 0/25] [ 203/ 273] time: 156.5354, d_loss: 1.38910055, g_loss: 0.69250935
[     205 Epoch:[ 0/25] [ 204/ 273] time: 157.2912, d_loss: 1.39123631, g_loss: 0.69258726
[     206 Epoch:[ 0/25] [ 205/ 273] time: 158.0500, d_loss: 1.38975334, g_loss: 0.69218135
[     207 Epoch:[ 0/25] [ 206/ 273] time: 158.8080, d_loss: 1.38911438, g_loss: 0.69775522
[     208 Epoch:[ 0/25] [ 207/ 273] time: 159.5712, d_loss: 1.38944304, g_loss: 0.69248807
[     209 Epoch:[ 0/25] [ 208/ 273] time: 160.3330, d_loss: 1.38945115, g_loss: 0.69177479
[     210 Epoch:[ 0/25] [ 209/ 273] time: 161.0886, d_loss: 1.38899446, g_loss: 0.69313759
[     211 Epoch:[ 0/25] [ 210/ 273] time: 161.8480, d_loss: 1.39046693, g_loss: 0.69016451
[     212 Epoch:[ 0/25] [ 211/ 273] time: 162.6106, d_loss: 1.39303052, g_loss: 0.69088024
[     213 Epoch:[ 0/25] [ 212/ 273] time: 163.3644, d_loss: 1.39447856, g_loss: 0.69028008
[     214 Epoch:[ 0/25] [ 213/ 273] time: 164.1182, d_loss: 1.39408803, g_loss: 0.68938220
[     215 Epoch:[ 0/25] [ 214/ 273] time: 164.8772, d_loss: 1.39358759, g_loss: 0.69049001
[     216 Epoch:[ 0/25] [ 215/ 273] time: 165.6265, d_loss: 1.39315176, g_loss: 0.68767977
[     217 Epoch:[ 0/25] [ 216/ 273] time: 166.3860, d_loss: 1.39203131, g_loss: 0.69344831
[     218 Epoch:[ 0/25] [ 217/ 273] time: 167.1411, d_loss: 1.39159822, g_loss: 0.68843251
[     219 Epoch:[ 0/25] [ 218/ 273] time: 167.8962, d_loss: 1.38793468, g_loss: 0.69543129
[     220 Epoch:[ 0/25] [ 219/ 273] time: 168.6643, d_loss: 1.38837862, g_loss: 0.69443929
[     221 Epoch:[ 0/25] [ 220/ 273] time: 169.4240, d_loss: 1.39055645, g_loss: 0.69421113
[     222 Epoch:[ 0/25] [ 221/ 273] time: 170.1695, d_loss: 1.38853896, g_loss: 0.69142985
[     223 Epoch:[ 0/25] [ 222/ 273] time: 170.9316, d_loss: 1.38899851, g_loss: 0.69189364
[     224 Epoch:[ 0/25] [ 223/ 273] time: 171.6914, d_loss: 1.38961744, g_loss: 0.69044018
[     225 Epoch:[ 0/25] [ 224/ 273] time: 172.4435, d_loss: 1.39288020, g_loss: 0.68884778
[     226 Epoch:[ 0/25] [ 225/ 273] time: 173.2174, d_loss: 1.39114380, g_loss: 0.69251823
[     227 Epoch:[ 0/25] [ 226/ 273] time: 173.9794, d_loss: 1.39227700, g_loss: 0.69145989
[     228 Epoch:[ 0/25] [ 227/ 273] time: 174.7262, d_loss: 1.39446902, g_loss: 0.69147342
[     229 Epoch:[ 0/25] [ 228/ 273] time: 175.4830, d_loss: 1.39622974, g_loss: 0.69499606
[     230 Epoch:[ 0/25] [ 229/ 273] time: 176.2430, d_loss: 1.39704204, g_loss: 0.69237381
[     231 Epoch:[ 0/25] [ 230/ 273] time: 176.9918, d_loss: 1.39742732, g_loss: 0.69580734
[     232 Epoch:[ 0/25] [ 231/ 273] time: 177.7558, d_loss: 1.39610517, g_loss: 0.68864226
[     233 Epoch:[ 0/25] [ 232/ 273] time: 178.5145, d_loss: 1.39819646, g_loss: 0.69241822
[     234 Epoch:[ 0/25] [ 233/ 273] time: 179.2643, d_loss: 1.39303386, g_loss: 0.69058484
[     235 Epoch:[ 0/25] [ 234/ 273] time: 180.0253, d_loss: 1.39100146, g_loss: 0.69111741
[     236 Epoch:[ 0/25] [ 235/ 273] time: 180.7850, d_loss: 1.38977122, g_loss: 0.69450992
[     237 Epoch:[ 0/25] [ 236/ 273] time: 181.5326, d_loss: 1.38906801, g_loss: 0.69384468
[     238 Epoch:[ 0/25] [ 237/ 273] time: 182.2926, d_loss: 1.38926077, g_loss: 0.69772327
[     239 Epoch:[ 0/25] [ 238/ 273] time: 183.0607, d_loss: 1.38954258, g_loss: 0.69477940
[     240 Epoch:[ 0/25] [ 239/ 273] time: 183.8046, d_loss: 1.39330149, g_loss: 0.69244969
[     241 Epoch:[ 0/25] [ 240/ 273] time: 184.5631, d_loss: 1.39348269, g_loss: 0.69332975
[     242 Epoch:[ 0/25] [ 241/ 273] time: 185.3239, d_loss: 1.39598894, g_loss: 0.69545388
[     243 Epoch:[ 0/25] [ 242/ 273] time: 186.0727, d_loss: 1.39495337, g_loss: 0.69136071
[     244 Epoch:[ 0/25] [ 243/ 273] time: 186.8298, d_loss: 1.39058685, g_loss: 0.69025671
[     245 Epoch:[ 0/25] [ 244/ 273] time: 187.5977, d_loss: 1.39710045, g_loss: 0.69646406
[     246 Epoch:[ 0/25] [ 245/ 273] time: 188.3456, d_loss: 1.40069222, g_loss: 0.69266218
[     247 Epoch:[ 0/25] [ 246/ 273] time: 189.1096, d_loss: 1.39547563, g_loss: 0.69380563
[     248 Epoch:[ 0/25] [ 247/ 273] time: 189.8800, d_loss: 1.39403367, g_loss: 0.69532472
[     249 Epoch:[ 0/25] [ 248/ 273] time: 190.6274, d_loss: 1.39091480, g_loss: 0.69329023
[     250 Epoch:[ 0/25] [ 249/ 273] time: 191.3803, d_loss: 1.39146054, g_loss: 0.69512582
[     251 Epoch:[ 0/25] [ 250/ 273] time: 192.1453, d_loss: 1.39005017, g_loss: 0.69621730
[     252 Epoch:[ 0/25] [ 251/ 273] time: 192.8922, d_loss: 1.38751686, g_loss: 0.69392937
[     253 Epoch:[ 0/25] [ 252/ 273] time: 193.6520, d_loss: 1.38651693, g_loss: 0.69175732
[     254 Epoch:[ 0/25] [ 253/ 273] time: 194.4160, d_loss: 1.38700604, g_loss: 0.69191957
[     255 Epoch:[ 0/25] [ 254/ 273] time: 195.1636, d_loss: 1.38738382, g_loss: 0.69092965
[     256 Epoch:[ 0/25] [ 255/ 273] time: 195.9239, d_loss: 1.38857925, g_loss: 0.69113803
[     257 Epoch:[ 0/25] [ 256/ 273] time: 196.6865, d_loss: 1.38979483, g_loss: 0.68849123
[     258 Epoch:[ 0/25] [ 257/ 273] time: 197.4375, d_loss: 1.39061952, g_loss: 0.68946028
[     259 Epoch:[ 0/25] [ 258/ 273] time: 198.1984, d_loss: 1.39690542, g_loss: 0.68999583
[     260 Epoch:[ 0/25] [ 259/ 273] time: 198.9658, d_loss: 1.40154195, g_loss: 0.69194794
[     261 Epoch:[ 0/25] [ 260/ 273] time: 199.7286, d_loss: 1.40109539, g_loss: 0.69519067
[     262 Epoch:[ 0/25] [ 261/ 273] time: 200.4832, d_loss: 1.40371990, g_loss: 0.69530541
[     263 Epoch:[ 0/25] [ 262/ 273] time: 201.2425, d_loss: 1.39336061, g_loss: 0.69280505
[     264 Epoch:[ 0/25] [ 263/ 273] time: 201.9897, d_loss: 1.39087200, g_loss: 0.69025207
[     265 Epoch:[ 0/25] [ 264/ 273] time: 202.7623, d_loss: 1.38954735, g_loss: 0.69039041
[     266 Epoch:[ 0/25] [ 265/ 273] time: 203.5188, d_loss: 1.38892913, g_loss: 0.69171822
[     267 Epoch:[ 0/25] [ 266/ 273] time: 204.2675, d_loss: 1.38890767, g_loss: 0.69280928
[     268 Epoch:[ 0/25] [ 267/ 273] time: 205.0313, d_loss: 1.38840032, g_loss: 0.69334769
[     269 Epoch:[ 0/25] [ 268/ 273] time: 205.7938, d_loss: 1.38846159, g_loss: 0.69505548
[     270 Epoch:[ 0/25] [ 269/ 273] time: 206.5403, d_loss: 1.38702035, g_loss: 0.69479841
[     271 Epoch:[ 0/25] [ 270/ 273] time: 207.3132, d_loss: 1.38786805, g_loss: 0.69219029
[     272 Epoch:[ 0/25] [ 271/ 273] time: 208.0734, d_loss: 1.38873434, g_loss: 0.69163758
[     273 Epoch:[ 0/25] [ 272/ 273] time: 208.8256, d_loss: 1.39154875, g_loss: 0.68647933
[     274 Epoch:[ 1/25] [   0/ 273] time: 209.5868, d_loss: 1.39016819, g_loss: 0.69022596
[     275 Epoch:[ 1/25] [   1/ 273] time: 210.3460, d_loss: 1.39183390, g_loss: 0.68792856
[     276 Epoch:[ 1/25] [   2/ 273] time: 211.0959, d_loss: 1.39129412, g_loss: 0.68990970
[     277 Epoch:[ 1/25] [   3/ 273] time: 211.8624, d_loss: 1.39031219, g_loss: 0.69068539
[     278 Epoch:[ 1/25] [   4/ 273] time: 212.6232, d_loss: 1.39145303, g_loss: 0.68931770
[     279 Epoch:[ 1/25] [   5/ 273] time: 213.3724, d_loss: 1.39057028, g_loss: 0.69135797
[     280 Epoch:[ 1/25] [   6/ 273] time: 214.1346, d_loss: 1.38991034, g_loss: 0.69163561
[     281 Epoch:[ 1/25] [   7/ 273] time: 214.8974, d_loss: 1.38969135, g_loss: 0.69016314
[     282 Epoch:[ 1/25] [   8/ 273] time: 215.6456, d_loss: 1.39106631, g_loss: 0.69244194
[     283 Epoch:[ 1/25] [   9/ 273] time: 216.4052, d_loss: 1.39060569, g_loss: 0.69080573
[     284 Epoch:[ 1/25] [  10/ 273] time: 217.1740, d_loss: 1.38983250, g_loss: 0.69217765
[     285 Epoch:[ 1/25] [  11/ 273] time: 217.9283, d_loss: 1.38865519, g_loss: 0.69469267
[     286 Epoch:[ 1/25] [  12/ 273] time: 218.6880, d_loss: 1.38798666, g_loss: 0.69691098
[     287 Epoch:[ 1/25] [  13/ 273] time: 219.4549, d_loss: 1.38668060, g_loss: 0.69617665
[     288 Epoch:[ 1/25] [  14/ 273] time: 220.2038, d_loss: 1.38519990, g_loss: 0.69420969
[     289 Epoch:[ 1/25] [  15/ 273] time: 220.9624, d_loss: 1.38436627, g_loss: 0.69391638
[     290 Epoch:[ 1/25] [  16/ 273] time: 221.7332, d_loss: 1.38535571, g_loss: 0.69245970
[     291 Epoch:[ 1/25] [  17/ 273] time: 222.4941, d_loss: 1.38723564, g_loss: 0.68905437
[     292 Epoch:[ 1/25] [  18/ 273] time: 223.2517, d_loss: 1.38896513, g_loss: 0.68981814
[     293 Epoch:[ 1/25] [  19/ 273] time: 224.0149, d_loss: 1.38944912, g_loss: 0.69092262
[     294 Epoch:[ 1/25] [  20/ 273] time: 224.7727, d_loss: 1.39145994, g_loss: 0.68861759
[     295 Epoch:[ 1/25] [  21/ 273] time: 225.5359, d_loss: 1.39227414, g_loss: 0.69309461
[     296 Epoch:[ 1/25] [  22/ 273] time: 226.2954, d_loss: 1.39294279, g_loss: 0.69072461
[     297 Epoch:[ 1/25] [  23/ 273] time: 227.0499, d_loss: 1.39247918, g_loss: 0.69220322
[     298 Epoch:[ 1/25] [  24/ 273] time: 227.8091, d_loss: 1.39263630, g_loss: 0.69377655
[     299 Epoch:[ 1/25] [  25/ 273] time: 228.5783, d_loss: 1.39171755, g_loss: 0.69652259
[     300 Epoch:[ 1/25] [  26/ 273] time: 229.3281, d_loss: 1.39250314, g_loss: 0.69378167
[     301 Epoch:[ 1/25] [  27/ 273] time: 230.0879, d_loss: 1.39111471, g_loss: 0.69500852
[     302 Epoch:[ 1/25] [  28/ 273] time: 230.8480, d_loss: 1.38962698, g_loss: 0.69279772
[     303 Epoch:[ 1/25] [  29/ 273] time: 231.6057, d_loss: 1.39029729, g_loss: 0.69480640
[     304 Epoch:[ 1/25] [  30/ 273] time: 232.3631, d_loss: 1.39031184, g_loss: 0.69610596
[     305 Epoch:[ 1/25] [  31/ 273] time: 233.1186, d_loss: 1.38734007, g_loss: 0.69674659
[     306 Epoch:[ 1/25] [  32/ 273] time: 233.8854, d_loss: 1.38748622, g_loss: 0.69353086
[     307 Epoch:[ 1/25] [  33/ 273] time: 234.6371, d_loss: 1.38728654, g_loss: 0.69343841
[     308 Epoch:[ 1/25] [  34/ 273] time: 235.3951, d_loss: 1.39009905, g_loss: 0.69104266
[     309 Epoch:[ 1/25] [  35/ 273] time: 236.1476, d_loss: 1.39025283, g_loss: 0.69022828
[     310 Epoch:[ 1/25] [  36/ 273] time: 236.9020, d_loss: 1.39134228, g_loss: 0.68994892
[     311 Epoch:[ 1/25] [  37/ 273] time: 237.6613, d_loss: 1.39104843, g_loss: 0.68933797
[     312 Epoch:[ 1/25] [  38/ 273] time: 238.4190, d_loss: 1.39126348, g_loss: 0.68852746
[     313 Epoch:[ 1/25] [  39/ 273] time: 239.1784, d_loss: 1.39097095, g_loss: 0.68803096
[     314 Epoch:[ 1/25] [  40/ 273] time: 239.9357, d_loss: 1.38966203, g_loss: 0.69142318
[     315 Epoch:[ 1/25] [  41/ 273] time: 240.6996, d_loss: 1.38957191, g_loss: 0.68932450
[     316 Epoch:[ 1/25] [  42/ 273] time: 241.4599, d_loss: 1.39053833, g_loss: 0.68957484
[     317 Epoch:[ 1/25] [  43/ 273] time: 242.2240, d_loss: 1.39374566, g_loss: 0.69619763
[     318 Epoch:[ 1/25] [  44/ 273] time: 242.9824, d_loss: 1.39775145, g_loss: 0.69459617
[     319 Epoch:[ 1/25] [  45/ 273] time: 243.7409, d_loss: 1.39360714, g_loss: 0.69813204
[     320 Epoch:[ 1/25] [  46/ 273] time: 244.4950, d_loss: 1.38957524, g_loss: 0.69391823
[     321 Epoch:[ 1/25] [  47/ 273] time: 245.2576, d_loss: 1.38731885, g_loss: 0.69611454
[     322 Epoch:[ 1/25] [  48/ 273] time: 246.0178, d_loss: 1.38553596, g_loss: 0.69460469
[     323 Epoch:[ 1/25] [  49/ 273] time: 246.7775, d_loss: 1.38717413, g_loss: 0.69307446
[     324 Epoch:[ 1/25] [  50/ 273] time: 247.5414, d_loss: 1.38922524, g_loss: 0.69165283
[     325 Epoch:[ 1/25] [  51/ 273] time: 248.2907, d_loss: 1.39189100, g_loss: 0.69229788
[     326 Epoch:[ 1/25] [  52/ 273] time: 249.0567, d_loss: 1.39189696, g_loss: 0.68972683
[     327 Epoch:[ 1/25] [  53/ 273] time: 249.8160, d_loss: 1.39311540, g_loss: 0.69197202
[     328 Epoch:[ 1/25] [  54/ 273] time: 250.5601, d_loss: 1.39235306, g_loss: 0.68782568
[     329 Epoch:[ 1/25] [  55/ 273] time: 251.3321, d_loss: 1.39060187, g_loss: 0.69602227
[     330 Epoch:[ 1/25] [  56/ 273] time: 252.0876, d_loss: 1.39126205, g_loss: 0.69065422
[     331 Epoch:[ 1/25] [  57/ 273] time: 252.8445, d_loss: 1.38834643, g_loss: 0.69395185
[     332 Epoch:[ 1/25] [  58/ 273] time: 253.6069, d_loss: 1.38935900, g_loss: 0.69417953
[     333 Epoch:[ 1/25] [  59/ 273] time: 254.3620, d_loss: 1.39026630, g_loss: 0.69208175
[     334 Epoch:[ 1/25] [  60/ 273] time: 255.1158, d_loss: 1.39009500, g_loss: 0.69333041
[     335 Epoch:[ 1/25] [  61/ 273] time: 255.8795, d_loss: 1.39009023, g_loss: 0.69171566
[     336 Epoch:[ 1/25] [  62/ 273] time: 256.6407, d_loss: 1.38994253, g_loss: 0.69037497
[     337 Epoch:[ 1/25] [  63/ 273] time: 257.3938, d_loss: 1.38936853, g_loss: 0.69309211
[     338 Epoch:[ 1/25] [  64/ 273] time: 258.1642, d_loss: 1.39059782, g_loss: 0.69160271
[     339 Epoch:[ 1/25] [  65/ 273] time: 258.9290, d_loss: 1.38893151, g_loss: 0.69333446
[     340 Epoch:[ 1/25] [  66/ 273] time: 259.6796, d_loss: 1.38816369, g_loss: 0.69413584
[     341 Epoch:[ 1/25] [  67/ 273] time: 260.4324, d_loss: 1.38781953, g_loss: 0.69331485
[     342 Epoch:[ 1/25] [  68/ 273] time: 261.1927, d_loss: 1.38790083, g_loss: 0.69266051
[     343 Epoch:[ 1/25] [  69/ 273] time: 261.9373, d_loss: 1.38747108, g_loss: 0.69130063
[     344 Epoch:[ 1/25] [  70/ 273] time: 262.6978, d_loss: 1.39023221, g_loss: 0.69038439
[     345 Epoch:[ 1/25] [  71/ 273] time: 263.4604, d_loss: 1.39027643, g_loss: 0.69034702
[     346 Epoch:[ 1/25] [  72/ 273] time: 264.2103, d_loss: 1.39047432, g_loss: 0.69437194
[     347 Epoch:[ 1/25] [  73/ 273] time: 264.9663, d_loss: 1.39281929, g_loss: 0.69107133
[     348 Epoch:[ 1/25] [  74/ 273] time: 265.7289, d_loss: 1.39070630, g_loss: 0.68963039
[     349 Epoch:[ 1/25] [  75/ 273] time: 266.4879, d_loss: 1.38937318, g_loss: 0.68939626
[     350 Epoch:[ 1/25] [  76/ 273] time: 267.2531, d_loss: 1.38895130, g_loss: 0.69033867
[     351 Epoch:[ 1/25] [  77/ 273] time: 268.0124, d_loss: 1.39089561, g_loss: 0.69076657
[     352 Epoch:[ 1/25] [  78/ 273] time: 268.7705, d_loss: 1.39030313, g_loss: 0.68942213
[     353 Epoch:[ 1/25] [  79/ 273] time: 269.5255, d_loss: 1.39018726, g_loss: 0.69129729
[     354 Epoch:[ 1/25] [  80/ 273] time: 270.2850, d_loss: 1.38986301, g_loss: 0.68971777
[     355 Epoch:[ 1/25] [  81/ 273] time: 271.0442, d_loss: 1.39046967, g_loss: 0.69484055
[     356 Epoch:[ 1/25] [  82/ 273] time: 271.8067, d_loss: 1.39076769, g_loss: 0.69538534
[     357 Epoch:[ 1/25] [  83/ 273] time: 272.5603, d_loss: 1.38970685, g_loss: 0.69580019
[     358 Epoch:[ 1/25] [  84/ 273] time: 273.3065, d_loss: 1.38829505, g_loss: 0.69534671
[     359 Epoch:[ 1/25] [  85/ 273] time: 274.0783, d_loss: 1.38762844, g_loss: 0.69387305
[     360 Epoch:[ 1/25] [  86/ 273] time: 274.8388, d_loss: 1.38615131, g_loss: 0.69457555
[     361 Epoch:[ 1/25] [  87/ 273] time: 275.5834, d_loss: 1.38630962, g_loss: 0.69235110
[     362 Epoch:[ 1/25] [  88/ 273] time: 276.3471, d_loss: 1.38775337, g_loss: 0.69278133
[     363 Epoch:[ 1/25] [  89/ 273] time: 277.1180, d_loss: 1.38800824, g_loss: 0.69297045
[     364 Epoch:[ 1/25] [  90/ 273] time: 277.8869, d_loss: 1.38751924, g_loss: 0.69248164
[     365 Epoch:[ 1/25] [  91/ 273] time: 278.6489, d_loss: 1.38732028, g_loss: 0.69112921
[     366 Epoch:[ 1/25] [  92/ 273] time: 279.4120, d_loss: 1.38860965, g_loss: 0.69172180
[     367 Epoch:[ 1/25] [  93/ 273] time: 280.1598, d_loss: 1.38633120, g_loss: 0.69198084
[     368 Epoch:[ 1/25] [  94/ 273] time: 280.9178, d_loss: 1.38760519, g_loss: 0.69191289
[     369 Epoch:[ 1/25] [  95/ 273] time: 281.6700, d_loss: 1.38706875, g_loss: 0.69140184
[     370 Epoch:[ 1/25] [  96/ 273] time: 282.4218, d_loss: 1.38906598, g_loss: 0.69071651
[     371 Epoch:[ 1/25] [  97/ 273] time: 283.1810, d_loss: 1.38797808, g_loss: 0.69270128
[     372 Epoch:[ 1/25] [  98/ 273] time: 283.9451, d_loss: 1.38869524, g_loss: 0.68970329
[     373 Epoch:[ 1/25] [  99/ 273] time: 284.6970, d_loss: 1.39128804, g_loss: 0.69295096
[     374 Epoch:[ 1/25] [ 100/ 273] time: 285.4521, d_loss: 1.39088392, g_loss: 0.69355392
[     375 Epoch:[ 1/25] [ 101/ 273] time: 286.2172, d_loss: 1.39123261, g_loss: 0.69436395
[     376 Epoch:[ 1/25] [ 102/ 273] time: 286.9714, d_loss: 1.39213586, g_loss: 0.69422638
[     377 Epoch:[ 1/25] [ 103/ 273] time: 287.7350, d_loss: 1.39302194, g_loss: 0.69315732
[     378 Epoch:[ 1/25] [ 104/ 273] time: 288.4957, d_loss: 1.39229512, g_loss: 0.69489264
[     379 Epoch:[ 1/25] [ 105/ 273] time: 289.2481, d_loss: 1.39252293, g_loss: 0.69016492
[     380 Epoch:[ 1/25] [ 106/ 273] time: 290.0013, d_loss: 1.39265585, g_loss: 0.69263816
[     381 Epoch:[ 1/25] [ 107/ 273] time: 290.7579, d_loss: 1.39076805, g_loss: 0.69066399
[     382 Epoch:[ 1/25] [ 108/ 273] time: 291.5176, d_loss: 1.38902938, g_loss: 0.69309872
[     383 Epoch:[ 1/25] [ 109/ 273] time: 292.2737, d_loss: 1.38649511, g_loss: 0.69262624
[     384 Epoch:[ 1/25] [ 110/ 273] time: 293.0314, d_loss: 1.38836217, g_loss: 0.69080085
[     385 Epoch:[ 1/25] [ 111/ 273] time: 293.7839, d_loss: 1.38859189, g_loss: 0.69219005
[     386 Epoch:[ 1/25] [ 112/ 273] time: 294.5373, d_loss: 1.39092028, g_loss: 0.69122440
[     387 Epoch:[ 1/25] [ 113/ 273] time: 295.2949, d_loss: 1.38919401, g_loss: 0.69048125
[     388 Epoch:[ 1/25] [ 114/ 273] time: 296.0596, d_loss: 1.39171052, g_loss: 0.69176722
[     389 Epoch:[ 1/25] [ 115/ 273] time: 296.8166, d_loss: 1.39349413, g_loss: 0.69122672
[     390 Epoch:[ 1/25] [ 116/ 273] time: 297.5721, d_loss: 1.39359021, g_loss: 0.69525957
[     391 Epoch:[ 1/25] [ 117/ 273] time: 298.3317, d_loss: 1.39697003, g_loss: 0.69650662
[     392 Epoch:[ 1/25] [ 118/ 273] time: 299.0815, d_loss: 1.39909816, g_loss: 0.69808251
[     393 Epoch:[ 1/25] [ 119/ 273] time: 299.8392, d_loss: 1.39557624, g_loss: 0.69223416WARNING:tensorflow:From /home/chenxubin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0522 00:58:09.145260 140124560234304 deprecation.py:323] From /home/chenxubin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
